{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import zipfile\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import importlib\n",
    "\n",
    "# import scipy.misc as misc\n",
    "# from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "img_size = 256\n",
    "#weights = None\n",
    "weights = 'imagenet'\n",
    "learning_rate = 1e-5\n",
    "EPOCHS = 2\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   img_id              input_img              label_img\n",
       " 0   10000  train_input_10000.png  train_label_10000.png\n",
       " 1   10001  train_input_10001.png  train_label_10001.png\n",
       " 2   10002  train_input_10002.png  train_label_10002.png\n",
       " 3   10003  train_input_10003.png  train_label_10003.png\n",
       " 4   10004  train_input_10004.png  train_label_10004.png,\n",
       "    img_id             input_img submission_name\n",
       " 0   20000  test_input_20000.png  test_20000.png\n",
       " 1   20001  test_input_20001.png  test_20001.png\n",
       " 2   20002  test_input_20002.png  test_20002.png\n",
       " 3   20003  test_input_20003.png  test_20003.png\n",
       " 4   20004  test_input_20004.png  test_20004.png)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('./data/train.csv')\n",
    "test_csv = pd.read_csv('./data/test.csv')\n",
    "train_csv.head(), test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_input_files = './data/train_input_img/'+train_csv['input_img']\n",
    "train_all_label_files = './data/train_label_img/'+train_csv['label_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 559 559\n",
      "Validation set size: 63 63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming train_all_input_files and train_all_label_files are NumPy arrays\n",
    "train_input_files, val_input_files, train_label_files, val_label_files = train_test_split(\n",
    "    train_all_input_files.to_numpy(),\n",
    "    train_all_label_files.to_numpy(),\n",
    "    test_size=0.1,  # Adjust the test_size parameter to control the validation set size\n",
    "    random_state=42  # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Now you have randomly split data\n",
    "print(\"Train set size:\", len(train_input_files), len(train_label_files))\n",
    "print(\"Validation set size:\", len(val_input_files), len(val_label_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이미지를 슬라이딩하며 256x256으로 잘라 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_img(img_path_list, save_path, stride):\n",
    "    os.makedirs(f'{save_path}{img_size}', exist_ok=True)\n",
    "    num = 0\n",
    "    for path in tqdm(img_path_list):\n",
    "        img = cv2.imread(path)\n",
    "        for top in range(0, img.shape[0], stride):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([img_size, img_size, 3], np.uint8)\n",
    "                temp = img[top:top+img_size, left:left+img_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                np.save(f'{save_path}{img_size}/{num}.npy', piece)\n",
    "                num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut_img(train_input_files, './data/train_input_img_', 128)\n",
    "#cut_img(train_label_files, './data/train_label_img_', 128)\n",
    "#cut_img(val_input_files, './data/val_input_img_', 128)\n",
    "#cut_img(val_label_files, './data/val_label_img_', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp_files = glob(f'./data/train_input_img_{img_size}/*.npy')\n",
    "train_targ_files = glob(f'./data/train_label_img_{img_size}/*.npy')\n",
    "\n",
    "val_inp_files = glob(f'./data/val_input_img_{img_size}/*.npy')\n",
    "val_targ_files = glob(f'./data/val_label_img_{img_size}/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167050, 167050, 19890, 19890)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inp_files, train_targ_files = shuffle(train_inp_files, train_targ_files, random_state=42)\n",
    "len(train_inp_files), len(train_targ_files),len(val_inp_files), len(val_targ_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 정규화 + 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 0 ~ 255를 0~1로 정규화\n",
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)/255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)/255\n",
    "    inp, targ = augmentation(inp, targ) # train 데이터 증강\n",
    "    return inp, targ\n",
    "\n",
    "#augmentation\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip_LR(inp, targ)\n",
    "    inp, targ = random_flip_UD(inp, targ)\n",
    "    inp, targ = random_crop(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "def random_rot(inp, targ): #rotate\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "    return inp, targ\n",
    "\n",
    "def random_flip_LR(inp, targ):# flip left, right\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ) \n",
    "    return inp, targ\n",
    "\n",
    "#추가\n",
    "def random_flip_UD(inp, targ):# flip up, down\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.flipud(inp)\n",
    "        targ = np.flipud(targ) \n",
    "    return inp, targ\n",
    "\n",
    "def random_crop(inp, targ, crop_size=(256, 256)):\n",
    "    h, w, _ = inp.shape\n",
    "\n",
    "    top = np.random.randint(0, h - crop_size[0])\n",
    "    left = np.random.randint(0, w - crop_size[1])\n",
    "    \n",
    "    bottom = top + crop_size[0]\n",
    "    right = left + crop_size[1]\n",
    "\n",
    "    inp = inp[top:bottom, left:right]\n",
    "    targ = targ[top:bottom, left:right]\n",
    "    return inp, targ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: high <= 0\nTraceback (most recent call last):\n\n  File \"c:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 7, in train_map_func\n    inp, targ = augmentation(inp, targ) # train 데이터 증강\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 15, in augmentation\n    inp, targ = random_crop(inp, targ)\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 42, in random_crop\n    top = np.random.randint(0, h - crop_size[0])\n\n  File \"mtrand.pyx\", line 746, in numpy.random.mtrand.RandomState.randint\n\n  File \"_bounded_integers.pyx\", line 1338, in numpy.random._bounded_integers._rand_int32\n\nValueError: high <= 0\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AAI\\Documents\\Github\\Dacon\\baseline\\1_ResNetV2+UNet.ipynb 셀 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AAI/Documents/Github/Dacon/baseline/1_ResNetV2%2BUNet.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AAI/Documents/Github/Dacon/baseline/1_ResNetV2%2BUNet.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# batch size, height, width, channle\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AAI/Documents/Github/Dacon/baseline/1_ResNetV2%2BUNet.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_dataset))[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape, \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_dataset))[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:761\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    760\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    762\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 744\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    745\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    746\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    747\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    749\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    751\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2727\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2725\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   2726\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 2727\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   2728\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   2729\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ValueError: high <= 0\nTraceback (most recent call last):\n\n  File \"c:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\AAI\\AppData\\Local\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 7, in train_map_func\n    inp, targ = augmentation(inp, targ) # train 데이터 증강\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 15, in augmentation\n    inp, targ = random_crop(inp, targ)\n\n  File \"C:\\Users\\AAI\\AppData\\Local\\Temp\\ipykernel_13408\\3440520456.py\", line 42, in random_crop\n    top = np.random.randint(0, h - crop_size[0])\n\n  File \"mtrand.pyx\", line 746, in numpy.random.mtrand.RandomState.randint\n\n  File \"_bounded_integers.pyx\", line 1338, in numpy.random._bounded_integers._rand_int32\n\nValueError: high <= 0\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inp_files, train_targ_files))\n",
    "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(train_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# batch size, height, width, channle\n",
    "next(iter(train_dataset))[0].shape, next(iter(train_dataset))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation 정규화\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)/255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)/255\n",
    "    return inp, targ\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inp_files, val_targ_files))\n",
    "val_dataset = val_dataset.map(lambda item1, item2: tf.numpy_function(val_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# batch size, height, width, channle\n",
    "next(iter(val_dataset))[0].shape, next(iter(val_dataset))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='LayerNormalization'\n",
    "\n",
    "def create_model(model_name):\n",
    "    from models.LayerNormalization import LayerNormalization\n",
    "    model = LayerNormalization(input_shape=(img_size, img_size, 3))\n",
    "    \n",
    "    # 모델 구조 이미지 저장\n",
    "    plot_model(model, to_file=model_name+'.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "model = create_model(model_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_true, y_pred, max_pixel = 1.0):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)\n",
    "\n",
    "loss_name='mae'\n",
    "# from loss.psnr_loss import psnr_loss\n",
    "# loss=psnr_loss\n",
    "\n",
    "optimizer_name='AdamW'\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "optimizer = AdamW(learning_rate)\n",
    "\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_name=model_name+'_'+loss_name+'_'+optimizer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join('save_models', save_path_name+'.h5'), \n",
    "                                                     monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "logdir = \"logs/\"+model_name+'_'+loss_name+'_'+optimizer_name+ datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, update_freq='epoch')\n",
    "hist = model.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset, callbacks=[callbacks_list, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('save_models',save_path_name+'.h5'), custom_objects={'psnr':psnr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"], label='train_loss')\n",
    "plt.plot(hist.history[\"val_loss\"], label='val_loss')\n",
    "plt.title('loss_plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(os.path.join('save_models', save_path_name+'.h5'),  custom_objects={'psnr': psnr})\n",
    "\n",
    "# batch_size=128\n",
    "def predict(img_paths, stride=32, batch_size=64):\n",
    "    results = []\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img.astype(np.float32)/255\n",
    "        crop = []\n",
    "        position = []\n",
    "        batch_count = 0\n",
    "\n",
    "        result_img = np.zeros_like(img)\n",
    "        voting_mask = np.zeros_like(img)\n",
    "\n",
    "        for top in tqdm(range(0, img.shape[0], stride)):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([img_size, img_size, 3], np.float32)\n",
    "                temp = img[top:top+img_size, left:left+img_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                crop.append(piece)\n",
    "                position.append([top, left])\n",
    "                batch_count += 1\n",
    "                if batch_count == batch_size:\n",
    "                    crop = np.array(crop)\n",
    "                    pred = model(crop)*255\n",
    "                    crop = []\n",
    "                    batch_count = 0\n",
    "                    for num, (t, l) in enumerate(position):\n",
    "                        piece = pred[num]\n",
    "                        h, w, c = result_img[t:t+img_size, l:l+img_size, :].shape\n",
    "                        result_img[t:t+img_size, l:l+img_size, :] += piece[:h, :w]\n",
    "                        voting_mask[t:t+img_size, l:l+img_size, :] += 1\n",
    "                    position = []\n",
    "        \n",
    "        result_img = result_img/voting_mask\n",
    "        result_img = result_img.astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        results.append(result_img)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidationSet 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 이미지에 대한 실험 결과\n",
    "result = predict(val_input_files[:5], stride=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_path, label_path) in enumerate(zip(val_input_files[:5], val_label_files[:5])):\n",
    "    input_img = cv2.imread(input_path)\n",
    "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "    targ_img = cv2.imread(label_path)\n",
    "    targ_img = cv2.cvtColor(targ_img, cv2.COLOR_BGR2RGB)\n",
    "    pred_img = result[i]\n",
    "    pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(input_img)\n",
    "    plt.title('input_img', fontsize=10)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(pred_img)\n",
    "    plt.title('output_img', fontsize=10)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(targ_img)\n",
    "    plt.title('target_img', fontsize=10)\n",
    "    plt.show()\n",
    "    print('input PSNR :', psnr(input_img.astype(float), targ_img.astype(float), 255).numpy())\n",
    "    print('output PSNR :', psnr(result[i].astype(float), targ_img.astype(float), 255).numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestSet 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_files = './data/test_input_img/'+test_csv['input_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = predict(test_input_files, stride=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, input_path in enumerate(test_input_files):\n",
    "    input_img = cv2.imread(input_path)\n",
    "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "    pred_img = test_result[i]\n",
    "    pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(input_img)\n",
    "    plt.title('input_img', fontsize=10)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(pred_img)\n",
    "    plt.title('output_img', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(result):\n",
    "    os.makedirs('submission/'+save_path_name, exist_ok=True)\n",
    "    os.chdir(\"./submission/\"+save_path_name+\"/\")\n",
    "    sub_imgs = []\n",
    "    for i, img in enumerate(result):\n",
    "        path = f'test_{20000+i}.png'\n",
    "        cv2.imwrite(path, img)\n",
    "        sub_imgs.append(path)\n",
    "    submission = zipfile.ZipFile(\"submission.zip\", 'w')\n",
    "    for path in sub_imgs:\n",
    "        submission.write(path)\n",
    "    submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
